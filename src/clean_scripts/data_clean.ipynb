{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Causes More Scientific Discoveries in Short Time\n",
    "\n",
    "## Data Clean\n",
    "\n",
    "- **Creating Author:** Yanheng Liu\n",
    "- **Latest Modification:** 13-04-2025  \n",
    "- **Modification Author:** Yanheng Liu  \n",
    "- **E-mail:** [yanheng.liu@etu.sorbonne-universite.fr](mailto:yanheng.liu@etu.sorbonne-universite.fr)  \n",
    "- **Version:** 1.2  \n",
    "\n",
    "---\n",
    "\n",
    "This is a data clean provided for the project in *DALAS* course.\n",
    "\n",
    "\n",
    "## Data Cleaning and Deduplication Workflow\n",
    "\n",
    "### Step 0: Check library installation\n",
    "\n",
    "### Step 1: Define Common Functions\n",
    "Includes text cleaning, normalization, and fuzzy matching functions.\n",
    "\n",
    "### Step 2: Load and Merge Data\n",
    "Reads three data files and merges them into a single DataFrame.\n",
    "\n",
    "### Step 3: Clean Punctuation\n",
    "Removes unnecessary punctuation from all columns (e.g., quotes), but keeps semicolons.\n",
    "\n",
    "### Step 4: Preview Country Names\n",
    "Displays original country names to check for inconsistencies manually.\n",
    "\n",
    "### Step 5: Standardize Country Names\n",
    "Uses a predefined mapping dictionary to unify country name variations.\n",
    "\n",
    "### Step 6: Preview Invention Categories\n",
    "Shows all original invention categories.\n",
    "\n",
    "### Step 7: Generalize Categories\n",
    "Maps specific invention categories to broader scientific fields, with detailed explanation.\n",
    "\n",
    "### Step 8: Normalize Key Text Fields\n",
    "Cleans and normalizes 'Name of Invention' and 'Name of Inventor' by lowering case and removing stopwords.\n",
    "\n",
    "### Step 9: Deduplicate Using Fuzzy Matching\n",
    "Groups similar invention names using fuzzy matching and merges records by combining field values.\n",
    "\n",
    "### Step 10: Output Final Dataset\n",
    "Displays the final cleaned dataset and saves it to a new CSV file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check package whether are installed in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already installed: requests\n",
      "Already installed: beautifulsoup4\n",
      "Already installed: pandas\n",
      "Already installed: tabulate\n",
      "Already installed: pdfplumber\n",
      "Already installed: lxml\n",
      "Already installed: pandas\n",
      "Already installed: fuzzywuzzy\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import subprocess\n",
    "\n",
    "# Read package list from requirements.txt\n",
    "with open(\"../../requirements.txt\", \"r\") as file:\n",
    "    packages = [line.strip() for line in file if line.strip() and not line.startswith(\"#\")]\n",
    "\n",
    "# Get the list of currently installed packages\n",
    "installed_packages = {pkg.key for pkg in pkg_resources.working_set}\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in packages:\n",
    "    pkg_name = package.split(\"==\")[0].lower() if \"==\" in package else package.lower()\n",
    "    if pkg_name not in installed_packages:\n",
    "        print(f\"Installing missing package: {package}\")\n",
    "        try:\n",
    "            subprocess.check_call([\"pip\", \"install\", package])\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to install {package}. Error: {e}\")\n",
    "    else:\n",
    "        print(f\"Already installed: {package}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Functions\n",
    "The cell is used to import pandas, re, string and fuzzywuzzy related functions, and defines common text preprocessing, punctuation cleaning, country normalisation, invention category classification, text normalisation and fuzzy matching and de-emphasis and other basic functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Define a translation table to remove punctuation except semicolon\n",
    "punctuations = string.punctuation.replace(\";\", \"\")  # keep semicolon\n",
    "trans_table = str.maketrans('', '', punctuations)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation from text except semicolon.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Remove punctuation using the translation table\n",
    "        return text.translate(trans_table).strip()\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def normalize_text(text, stopwords=None):\n",
    "    \"\"\"Normalize text: lower-case, remove punctuation and stopwords, and extra spaces.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # lower-case\n",
    "    text = text.lower()\n",
    "    # remove punctuation (except semicolon)\n",
    "    text = text.translate(trans_table)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    if stopwords:\n",
    "        # remove stopwords provided as a set\n",
    "        tokens = text.split()\n",
    "        tokens = [t for t in tokens if t not in stopwords]\n",
    "        text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "def standardize_country(country_str, mapping):\n",
    "    \"\"\"\n",
    "    Standardize country names.\n",
    "    Split multiple countries by semicolon, map each to official name, then return unique sorted values.\n",
    "    \"\"\"\n",
    "    if not isinstance(country_str, str):\n",
    "        return country_str\n",
    "    # Split by semicolon and possibly comma if there is complex cases\n",
    "    parts = re.split(r'[;，,]', country_str)\n",
    "    standardized = []\n",
    "    for part in parts:\n",
    "        # Remove leading and trailing spaces and convert to lower case\n",
    "        part_clean = part.strip().lower()\n",
    "        if part_clean in mapping:\n",
    "            standardized.append(mapping[part_clean])\n",
    "        else:\n",
    "            # If not in the mapping, capitalise the first letter.\n",
    "            standardized.append(part_clean.title())\n",
    "    # De-weighting and sorting before joining with a semicolon\n",
    "    standardized = sorted(set(standardized))\n",
    "    return \"; \".join(standardized)\n",
    "\n",
    "def generalize_category(cat):\n",
    "    \"\"\"\n",
    "    Map detailed invention categories into broad categories.\n",
    "    Matching is case‐insensitive and covers all specified categories.\n",
    "    \"\"\"\n",
    "    if not isinstance(cat, str):\n",
    "        return 'Other'\n",
    "    s = cat.strip().lower()\n",
    "    mapping_rules = [\n",
    "        # Physical Sciences\n",
    "        (r'\\b('\n",
    "         r'physics|astronomy|astrophysics|cosmology|geophysics|'\n",
    "         r'nuclear(?: science| physics| weapons| fusion)?|radiometric|'\n",
    "         r'chaos theory|optics|thermodynamics|acoustics|paleontology|'\n",
    "         r'measurement instrument|scientific imaging|scientific theory|'\n",
    "         r'astronomical theory|scientific model|electricity'\n",
    "         r')\\b',\n",
    "         'Physical Sciences'),\n",
    "\n",
    "        # Chemistry & Materials\n",
    "        (r'\\b('\n",
    "         r'chemistry|biochemistry|electrochemistry|chemical engineering|'\n",
    "         r'materials science|materials technology|metallurgical engineering|'\n",
    "         r'metallurgical process|metallurgy|explosives|explosive technology|'\n",
    "         r'paper technology|battery technology|polymer material|plastic material|'\n",
    "         r'flooring material|chemical discovery|chemical process|ammunition|'\n",
    "         r'chemical element|nanotechnology|textile fiber'\n",
    "         r')\\b',\n",
    "         'Chemistry & Materials'),\n",
    "\n",
    "        # Life Sciences & Medicine\n",
    "        (r'\\b('\n",
    "         r'biology|molecular biology|microbiology|genetics|genomics|'\n",
    "         r'evolutionary biology|physiology|neuroscience|neurology|virology|'\n",
    "         r'immunology|medicine|medical imaging|medical instrument|'\n",
    "         r'medical anaesthetic|medical equipment|pharmaceuticals|biotechnology'\n",
    "         r')\\b',\n",
    "         'Life Sciences & Medicine'),\n",
    "\n",
    "        # Earth & Environmental Sciences\n",
    "        (r'\\b('\n",
    "         r'geology|climatology|climate science|environmental science|'\n",
    "         r'oceanography|sanitation technology'\n",
    "         r')\\b',\n",
    "         'Earth & Environmental Sciences'),\n",
    "\n",
    "        # Agricultural Sciences & Technology\n",
    "        (r'\\b('\n",
    "         r'agriculture|agricultural machinery|agricultural engineering|'\n",
    "         r'agricultural implement|agricultural technology|agricultural chemistry|'\n",
    "         r'agricultural fencing|food technology|food safety process'\n",
    "         r')\\b',\n",
    "         'Agricultural Sciences & Technology'),\n",
    "\n",
    "        # Engineering & Technology\n",
    "        (r'\\b('\n",
    "         r'mechanical engineering|electrical engineering|electronic engineering|'\n",
    "         r'civil engineering|construction engineering|structural engineering|'\n",
    "         r'aerospace engineering|aerospace|mining engineering|industrial engineering|'\n",
    "         r'hydraulic engineering|aviation(?: technology)?|aeronautical vehicle|'\n",
    "         r'aeronautical device|rocketry|marine technology|marine navigation|'\n",
    "         r'marine safety equipment|automotive technology|transportation(?: engineering)?|'\n",
    "         r'transportation safety device|transport system|railway carriage|'\n",
    "         r'vehicle innovation|vehicle|construction materials|energy storage device|'\n",
    "         r'3d printing|diving technology|electric motor|household appliance|'\n",
    "         r'industrial design|lighting device|military technology|mining technology|'\n",
    "         r'space technology|technical drawing|timekeeping mechanism|timekeeping technology|'\n",
    "         r'refrigeration technology|domestic technology|home appliances?|consumer electronics|'\n",
    "         r'printing technology|printing machinery|industrial machinery|industrial process|'\n",
    "         r'machine tools?|textile machinery|garment technology|clothing|welding technology|'\n",
    "         r'lock technology|firearms? technology|weapon technology|sports equipment|turbine|'\n",
    "         r'engine|logistics|vertical transportation|vertical transportation safety|'\n",
    "         r'assistive technology|safety technology|security device|chemical safety device|'\n",
    "         r'electromechanical device|kitchen utensil|cleaning device|personal accessory|'\n",
    "         r'personal grooming|packaging|office equipment|energy technology|renewable energy|'\n",
    "         r'oil and gas|fuel'\n",
    "         r')\\b',\n",
    "         'Engineering & Technology'),\n",
    "\n",
    "        # Information & Computing\n",
    "        (r'\\b('\n",
    "         r'computing|computer science|computer engineering|computer hardware|'\n",
    "         r'computer networking|networking technology|software|internet technology|'\n",
    "         r'information technology|mobile technology|wireless communication|'\n",
    "         r'telecommunications|communication technology|communication device|'\n",
    "         r'communication system|communications|blockchain technology|'\n",
    "         r'artificial intelligence|quantum computing|cryptography|financial technology|'\n",
    "         r'data storage|digital storage|optical storage|computer interface|'\n",
    "         r'touchscreen technology'\n",
    "         r')\\b',\n",
    "         'Information & Computing'),\n",
    "\n",
    "        # Arts & Media\n",
    "        (r'\\b('\n",
    "         r'music|musical instrument|film technology|photography|photographic process|'\n",
    "         r'television technology|audio technology|audio device|audio recording device|'\n",
    "         r'audio playback device|video games|recreational technology|toys?|sports equipment'\n",
    "         r')\\b',\n",
    "         'Arts & Media'),\n",
    "\n",
    "        # Social Sciences & Humanities\n",
    "        (r'\\b(anthropology|ethology|paleoanthropology)\\b',\n",
    "         'Social Sciences & Humanities'),\n",
    "\n",
    "        # Mathematics\n",
    "        (r'\\b(mathematics|math)\\b',\n",
    "         'Mathematics'),\n",
    "    ]\n",
    "\n",
    "    for pattern, label in mapping_rules:\n",
    "        if re.search(pattern, s):\n",
    "            return label\n",
    "    return 'Other'\n",
    "    \n",
    "def merge_dict_values(rows):\n",
    "    \"\"\"\n",
    "    Merge a list of values (e.g., country, inventor, etc.) by taking unique values and joining them with semicolon.\n",
    "    \"\"\"\n",
    "    merged = set()\n",
    "    for item in rows:\n",
    "        if isinstance(item, str):\n",
    "            # Splitting possible composite entries\n",
    "            parts = re.split(r'[;，,]', item)\n",
    "            for part in parts:\n",
    "                merged.add(part.strip())\n",
    "        else:\n",
    "            merged.add(str(item).strip())\n",
    "    return \"; \".join(sorted(merged))\n",
    "\n",
    "# Define a set of stopwords to remove in text cleaning for invention names\n",
    "stopwords = set(['the', 'for', 'of', 'and', 'in', 'on', 'origin', 'proposed', 'idea', 'first'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV files and merge data\n",
    "This cell reads three separate CSV files from this directory and merges them into a single DataFrame for unified processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of origin data:  823\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../../raw_data/clean_data/clean_data_yann_1.csv')\n",
    "df2 = pd.read_csv('../../raw_data/clean_data/clean_data_yann_2.csv')\n",
    "df3 = pd.read_csv('../../raw_data/clean_data/clean_data_yann_3.csv')\n",
    "df4 = pd.read_csv('../../raw_data/clean_data/clean_data_balam.csv')\n",
    "\n",
    "# Concatenate all data into one DataFrame\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "print(\"number of origin data: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleansing the data, removing punctuation and redundant spaces other than semicolons from each field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name of Invention</th>\n",
       "      <th>Name of Inventor</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Quantum theory proposed</td>\n",
       "      <td>Planck</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>AustrianAmerican</td>\n",
       "      <td>Discovery of human blood groups</td>\n",
       "      <td>Landsteiner</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Waveparticle duality of light</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Special theory of relativity</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1906</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Existence of vitamins proposed</td>\n",
       "      <td>Hopkins</td>\n",
       "      <td>Biochemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Country                Name of Invention Name of Inventor  \\\n",
       "0  1900           Germany          Quantum theory proposed           Planck   \n",
       "1  1901  AustrianAmerican  Discovery of human blood groups      Landsteiner   \n",
       "2  1905           Germany    Waveparticle duality of light         Einstein   \n",
       "3  1905           Germany     Special theory of relativity         Einstein   \n",
       "4  1906    United Kingdom   Existence of vitamins proposed          Hopkins   \n",
       "\n",
       "       Category  \n",
       "0       Physics  \n",
       "1      Medicine  \n",
       "2       Physics  \n",
       "3       Physics  \n",
       "4  Biochemistry  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Punctuation cleaning for all string type fields\n",
    "for col in df_clean.columns:\n",
    "    df_clean[col] = df_clean[col].apply(remove_punctuation)\n",
    "\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export all country names for inspection\n",
    "Extract unique values by combining all country fields into a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of original country names:\n",
      "Australia\n",
      "Australia; Switzerland\n",
      "Austria\n",
      "Austria; Netherlands\n",
      "Austria; Sweden\n",
      "AustrianAmerican\n",
      "Belgium\n",
      "Belgium; France\n",
      "Belgium; United States\n",
      "Britain\n",
      "Bulgaria\n",
      "Canada\n",
      "Canada; United States\n",
      "China\n",
      "Croatia\n",
      "Czech\n",
      "Czechia\n",
      "Denmark\n",
      "Egyptian; Korean\n",
      "England\n",
      "Finland\n",
      "France\n",
      "France; Germany; United Kingdom\n",
      "France; United Kingdom\n",
      "Germany\n",
      "Germany; Austria\n",
      "Germany; Canada\n",
      "Germany; Denmark; Germany; Germany; Austria\n",
      "Germany; France\n",
      "Germany; Switzerland; United States\n",
      "Germany; USA\n",
      "Germany; United Kingdom\n",
      "Germany; United States\n",
      "Hungarian; British\n",
      "Hungary\n",
      "Hungary; United Kingdom\n",
      "India\n",
      "International\n",
      "Ireland\n",
      "Ireland; United States\n",
      "Israel\n",
      "Italy\n",
      "Italy; Germany\n",
      "Italy; United States\n",
      "Japan\n",
      "Japan; Dutch\n",
      "Japan; USA\n",
      "Mexico; USA\n",
      "Multiple\n",
      "Netherlands\n",
      "Netherlands; Japan\n",
      "Netherlands; Switzerland\n",
      "New Zealand\n",
      "New Zealand; United Kingdom\n",
      "Norway\n",
      "Norway; United States\n",
      "Poland\n",
      "Poland; Canada\n",
      "Poland; France\n",
      "Poland; Germany\n",
      "Poland; United States\n",
      "Romania\n",
      "Russia\n",
      "Russia; USA\n",
      "Russia; United Kingdom\n",
      "Russia; United States\n",
      "Scotland\n",
      "Scotland; Canada; United States\n",
      "Serbia\n",
      "Serbia; United States\n",
      "South Korea\n",
      "Soviet Union\n",
      "Sweden\n",
      "Switzerland\n",
      "USA\n",
      "USA; England\n",
      "USA; France\n",
      "USA; Germany\n",
      "USA; International\n",
      "USA; Japan\n",
      "USA; Pakistan\n",
      "USA; USA; Canada\n",
      "USA; United Kingdom\n",
      "United Kingdom\n",
      "United Kingdom; Australia\n",
      "United Kingdom; Belgium\n",
      "United Kingdom; France\n",
      "United Kingdom; Germany\n",
      "United Kingdom; USA\n",
      "United Kingdom; United States\n",
      "United Kingdom; United States; Israel\n",
      "United States\n",
      "United States; Australia\n",
      "United States; China\n",
      "United States; France\n",
      "United States; France; Japan\n",
      "United States; Germany\n",
      "United States; Italy\n",
      "United States; United Kingdom\n",
      "Wales\n"
     ]
    }
   ],
   "source": [
    "all_countries = df_clean['Country'].dropna().unique()\n",
    "print(\"List of original country names:\")\n",
    "for country in sorted(all_countries):\n",
    "    print(country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardised Country Names\n",
    "Define country similar name mapping (all keys are lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardised list of country names:\n",
      "- Australia\n",
      "- Australia; Switzerland\n",
      "- Australia; United Kingdom\n",
      "- Australia; United States\n",
      "- Austria\n",
      "- Austria; Denmark; Germany\n",
      "- Austria; Germany\n",
      "- Austria; Netherlands\n",
      "- Austria; Sweden\n",
      "- Austrianamerican\n",
      "- Belgium\n",
      "- Belgium; France\n",
      "- Belgium; United Kingdom\n",
      "- Belgium; United States\n",
      "- Bulgaria\n",
      "- Canada\n",
      "- Canada; Germany\n",
      "- Canada; Poland\n",
      "- Canada; United Kingdom; United States\n",
      "- Canada; United States\n",
      "- China\n",
      "- China; United States\n",
      "- Croatia\n",
      "- Czech\n",
      "- Czechia\n",
      "- Denmark\n",
      "- Egypt; South Korea\n",
      "- Finland\n",
      "- France\n",
      "- France; Germany\n",
      "- France; Germany; United Kingdom\n",
      "- France; Japan; United States\n",
      "- France; Poland\n",
      "- France; United Kingdom\n",
      "- France; United States\n",
      "- Germany\n",
      "- Germany; Italy\n",
      "- Germany; Poland\n",
      "- Germany; Switzerland; United States\n",
      "- Germany; United Kingdom\n",
      "- Germany; United States\n",
      "- Hungary\n",
      "- Hungary; United Kingdom\n",
      "- India\n",
      "- International\n",
      "- International; United States\n",
      "- Ireland\n",
      "- Ireland; United States\n",
      "- Israel\n",
      "- Israel; United Kingdom; United States\n",
      "- Italy\n",
      "- Italy; United States\n",
      "- Japan\n",
      "- Japan; Netherlands\n",
      "- Japan; United States\n",
      "- Mexico; United States\n",
      "- Multiple\n",
      "- Netherlands\n",
      "- Netherlands; Switzerland\n",
      "- New Zealand\n",
      "- New Zealand; United Kingdom\n",
      "- Norway\n",
      "- Norway; United States\n",
      "- Pakistan; United States\n",
      "- Poland\n",
      "- Poland; United States\n",
      "- Romania\n",
      "- Russia\n",
      "- Russia; United Kingdom\n",
      "- Russia; United States\n",
      "- Serbia\n",
      "- Serbia; United States\n",
      "- South Korea\n",
      "- Sweden\n",
      "- Switzerland\n",
      "- United Kingdom\n",
      "- United Kingdom; United States\n",
      "- United States\n"
     ]
    }
   ],
   "source": [
    "# Expanded mapping of variants and demonyms to a single canonical name\n",
    "country_mapping = {\n",
    "    \"british\": \"United Kingdom\",\n",
    "    \"britain\": \"United Kingdom\",\n",
    "    \"england\": \"United Kingdom\",\n",
    "    \"wales\": \"United Kingdom\",\n",
    "    \"scotland\": \"United Kingdom\",\n",
    "    \"uk\": \"United Kingdom\",\n",
    "    \"united kingdom\": \"United Kingdom\",\n",
    "    \"usa\": \"United States\",\n",
    "    \"us\": \"United States\",\n",
    "    \"american\": \"United States\",\n",
    "    \"united states\": \"United States\",\n",
    "    \"soviet union\": \"Russia\",\n",
    "    \"austrian\": \"Austria\",\n",
    "    \"hungarian\": \"Hungary\",\n",
    "    \"egyptian\": \"Egypt\",\n",
    "    \"korean\": \"South Korea\",\n",
    "    \"dutch\": \"Netherlands\",\n",
    "    # special case: hyphenated demonyms\n",
    "    \"austrian-american\": \"Austria; United States\",\n",
    "    # preserve literal tokens\n",
    "    \"international\": \"International\",\n",
    "    \"multiple\": \"Multiple\"\n",
    "}\n",
    "\n",
    "# Apply the already-defined standardize_country function\n",
    "df_clean['Country'] = df_clean['Country'].apply(lambda x: standardize_country(x, country_mapping))\n",
    "\n",
    "# Print out the final sorted list of unique country names\n",
    "std_countries = sorted(df_clean['Country'].dropna().unique())\n",
    "\n",
    "print(\"Standardised list of country names:\")\n",
    "for country in std_countries:\n",
    "    print(f\"- {country}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export all original invention categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of original invention categories:\n",
      "3D Printing\n",
      "Acoustics\n",
      "Aeronautical Device\n",
      "Aeronautical Vehicle\n",
      "Aerospace\n",
      "Aerospace Engineering\n",
      "Agricultural Chemistry\n",
      "Agricultural Engineering\n",
      "Agricultural Fencing\n",
      "Agricultural Implement\n",
      "Agricultural Machinery\n",
      "Agricultural Technology\n",
      "Agriculture\n",
      "Ammunition\n",
      "Anthropology\n",
      "Artificial Intelligence\n",
      "Assistive Technology\n",
      "Astronomical Theory\n",
      "Astronomy\n",
      "Astrophysics\n",
      "Audio Device\n",
      "Audio Playback Device\n",
      "Audio Recording Device\n",
      "Audio Technology\n",
      "Automotive Technology\n",
      "Aviation\n",
      "Aviation Technology\n",
      "Battery Technology\n",
      "Biochemistry\n",
      "Biology\n",
      "Biotechnology\n",
      "Blockchain Technology\n",
      "Chaos Theory\n",
      "Chemical Discovery\n",
      "Chemical Element\n",
      "Chemical Engineering\n",
      "Chemical Process\n",
      "Chemical Safety Device\n",
      "Chemistry\n",
      "Civil Engineering\n",
      "Cleaning Device\n",
      "Climate Science\n",
      "Climatology\n",
      "Clothing\n",
      "Communication Device\n",
      "Communication System\n",
      "Communication Technology\n",
      "Communications\n",
      "Computer Engineering\n",
      "Computer Hardware\n",
      "Computer Interface\n",
      "Computer Networking\n",
      "Computer Science\n",
      "Computing\n",
      "Construction Engineering\n",
      "Construction Material\n",
      "Construction Materials\n",
      "Consumer Electronics\n",
      "Cosmology\n",
      "Cryptography\n",
      "Data Storage\n",
      "Digital Storage\n",
      "Diving Technology\n",
      "Domestic Technology\n",
      "Electric Motor\n",
      "Electrical Engineering\n",
      "Electricity\n",
      "Electrochemistry\n",
      "Electromechanical Device\n",
      "Electronic Engineering\n",
      "Electronics\n",
      "Energy Storage Device\n",
      "Energy Technology\n",
      "Engine\n",
      "Environmental Science\n",
      "Ethology\n",
      "Evolutionary Biology\n",
      "Explosive Technology\n",
      "Explosives\n",
      "Film Technology\n",
      "Financial Technology\n",
      "Firearm Technology\n",
      "Firearms Technology\n",
      "Flooring Material\n",
      "Food Safety Process\n",
      "Food Technology\n",
      "Fuel\n",
      "Garment Technology\n",
      "Genetics\n",
      "Genomics\n",
      "Geology\n",
      "Geophysics\n",
      "Home Appliance\n",
      "Home Appliances\n",
      "Horology\n",
      "Household Appliance\n",
      "Hydraulic Engineering\n",
      "Immunology\n",
      "Industrial Design\n",
      "Industrial Engineering\n",
      "Industrial Machinery\n",
      "Industrial Process\n",
      "Information Technology\n",
      "Internet Technology\n",
      "Kitchen Utensil\n",
      "Laser Technology\n",
      "Lighting Device\n",
      "Lock Technology\n",
      "Logistics\n",
      "Machine Tool\n",
      "Machine Tools\n",
      "Marine Navigation\n",
      "Marine Safety Equipment\n",
      "Marine Technology\n",
      "Materials Science\n",
      "Materials Technology\n",
      "Mathematics\n",
      "Measurement Instrument\n",
      "Mechanical Engineering\n",
      "Medical Anaesthetic\n",
      "Medical Equipment\n",
      "Medical Imaging\n",
      "Medical Instrument\n",
      "Medicine\n",
      "Metallurgical Engineering\n",
      "Metallurgical Furnace\n",
      "Metallurgical Process\n",
      "Metallurgy\n",
      "Microbiology\n",
      "Microwave Technology\n",
      "Military Technology\n",
      "Mining Engineering\n",
      "Mining Technology\n",
      "Mobile Technology\n",
      "Molecular Biology\n",
      "Music\n",
      "Musical Instrument\n",
      "Nanotechnology\n",
      "Navigation Technology\n",
      "Networking Technology\n",
      "Neurology\n",
      "Neuroscience\n",
      "Nuclear Fusion\n",
      "Nuclear Physics\n",
      "Nuclear Science\n",
      "Nuclear Weapons\n",
      "Oceanography\n",
      "Office Equipment\n",
      "Oil and Gas\n",
      "Optical Storage\n",
      "Optics\n",
      "Optoelectronics\n",
      "Packaging\n",
      "Paleoanthropology\n",
      "Paleontology\n",
      "Paper Technology\n",
      "Particle Physics\n",
      "Personal Accessory\n",
      "Personal Grooming\n",
      "Pharmaceuticals\n",
      "Photographic Process\n",
      "Photography\n",
      "Physics\n",
      "Physiology\n",
      "Plastic Material\n",
      "Polymer Material\n",
      "Printing Machinery\n",
      "Printing Technology\n",
      "Quantum Computing\n",
      "Radiometric Dating\n",
      "Railway Carriage\n",
      "Recreational Technology\n",
      "Refrigeration Technology\n",
      "Renewable Energy\n",
      "Rocketry\n",
      "Safety Technology\n",
      "Sanitation Technology\n",
      "Scientific Imaging\n",
      "Scientific Model\n",
      "Scientific Theory\n",
      "Security Device\n",
      "Semiconductor Technology\n",
      "Software\n",
      "Space Technology\n",
      "Sports Equipment\n",
      "Structural Engineering\n",
      "Technical Drawing\n",
      "Telecommunications\n",
      "Television Technology\n",
      "Textile Fiber\n",
      "Textile Machinery\n",
      "Theoretical Physics\n",
      "Thermodynamics\n",
      "Timekeeping Mechanism\n",
      "Timekeeping Technology\n",
      "Touchscreen Technology\n",
      "Toy\n",
      "Toys\n",
      "Transport System\n",
      "Transportation\n",
      "Transportation Engineering\n",
      "Transportation Safety Device\n",
      "Turbine\n",
      "Vehicle\n",
      "Vehicle Innovation\n",
      "Vertical Transportation\n",
      "Vertical Transportation Safety\n",
      "Video Games\n",
      "Virology\n",
      "Weapon Technology\n",
      "Welding Technology\n",
      "Wireless Communication\n"
     ]
    }
   ],
   "source": [
    "all_categories = df_clean['Category'].dropna().unique()\n",
    "print(\"List of original invention categories:\")\n",
    "for cat in sorted(all_categories):\n",
    "    print(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate invention categories into general categories\n",
    "Apply the generalize_category function to the Category column and create a new column General_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Category Statistics:\n",
      "General_Category\n",
      "Engineering & Technology              299\n",
      "Physical Sciences                     128\n",
      "Chemistry & Materials                  98\n",
      "Information & Computing                92\n",
      "Life Sciences & Medicine               87\n",
      "Arts & Media                           46\n",
      "Other                                  27\n",
      "Agricultural Sciences & Technology     22\n",
      "Earth & Environmental Sciences         18\n",
      "Social Sciences & Humanities            5\n",
      "Mathematics                             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_clean['General_Category'] = df_clean['Category'].apply(generalize_category)\n",
    "\n",
    "# Print the statistics of the transformed categories\n",
    "print(\"General Category Statistics:\")\n",
    "print(df_clean['General_Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and normalization (unifying case, removing stopwords and whitespace, etc.)\n",
    "Normalize 'Name of Invention' as a basis for later deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name of Invention</th>\n",
       "      <th>Name of Inventor</th>\n",
       "      <th>Category</th>\n",
       "      <th>General_Category</th>\n",
       "      <th>Invention_Norm</th>\n",
       "      <th>Inventor_Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Quantum theory proposed</td>\n",
       "      <td>Planck</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>quantum theory</td>\n",
       "      <td>planck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Austrianamerican</td>\n",
       "      <td>Discovery of human blood groups</td>\n",
       "      <td>Landsteiner</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Life Sciences &amp; Medicine</td>\n",
       "      <td>discovery human blood groups</td>\n",
       "      <td>landsteiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Waveparticle duality of light</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>waveparticle duality light</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Special theory of relativity</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>special theory relativity</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1906</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Existence of vitamins proposed</td>\n",
       "      <td>Hopkins</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>Chemistry &amp; Materials</td>\n",
       "      <td>existence vitamins</td>\n",
       "      <td>hopkins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Country                Name of Invention Name of Inventor  \\\n",
       "0  1900           Germany          Quantum theory proposed           Planck   \n",
       "1  1901  Austrianamerican  Discovery of human blood groups      Landsteiner   \n",
       "2  1905           Germany    Waveparticle duality of light         Einstein   \n",
       "3  1905           Germany     Special theory of relativity         Einstein   \n",
       "4  1906    United Kingdom   Existence of vitamins proposed          Hopkins   \n",
       "\n",
       "       Category          General_Category                Invention_Norm  \\\n",
       "0       Physics         Physical Sciences                quantum theory   \n",
       "1      Medicine  Life Sciences & Medicine  discovery human blood groups   \n",
       "2       Physics         Physical Sciences    waveparticle duality light   \n",
       "3       Physics         Physical Sciences     special theory relativity   \n",
       "4  Biochemistry     Chemistry & Materials            existence vitamins   \n",
       "\n",
       "  Inventor_Norm  \n",
       "0        planck  \n",
       "1   landsteiner  \n",
       "2      einstein  \n",
       "3      einstein  \n",
       "4       hopkins  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_clean['Invention_Norm'] = df_clean['Name of Invention'].apply(lambda x: normalize_text(x, stopwords=stopwords))\n",
    "# Similarly, normalize 'Name of Inventor' if needed\n",
    "df_clean['Inventor_Norm'] = df_clean['Name of Inventor'].apply(lambda x: normalize_text(x))\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform data deduplication using a fuzzy matching algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records before deduplication: 823\n",
      "Number of records after deduplication: 757\n"
     ]
    }
   ],
   "source": [
    "def deduplicate_df(df, threshold=90):\n",
    "    \"\"\"\n",
    "    Use fuzzy matching to group similar invention names and merge rows.\n",
    "    The merging is performed by taking the union of all other column values.\n",
    "    \"\"\"\n",
    "    groups = []  # list to store groups, each group is a list of row indices\n",
    "    # List of normalized invention names\n",
    "    names = df['Invention_Norm'].tolist()\n",
    "    used_idx = set()\n",
    "    \n",
    "    for idx, name in enumerate(names):\n",
    "        if idx in used_idx:\n",
    "            continue\n",
    "        # Create a new group with the current index\n",
    "        group = [idx]\n",
    "        used_idx.add(idx)\n",
    "        for jdx in range(idx+1, len(names)):\n",
    "            if jdx in used_idx:\n",
    "                continue\n",
    "            # Compute fuzzy ratio between two normalized strings\n",
    "            ratio = fuzz.ratio(name, names[jdx])\n",
    "            if ratio >= threshold:\n",
    "                group.append(jdx)\n",
    "                used_idx.add(jdx)\n",
    "        groups.append(group)\n",
    "    \n",
    "    # Merge groups: for each group, merge the corresponding rows\n",
    "    merged_records = []\n",
    "    for group in groups:\n",
    "        # If the group has only one record, keep it as is\n",
    "        if len(group) == 1:\n",
    "            merged_records.append(df.iloc[group[0]])\n",
    "        else:\n",
    "            # Merge each column (join values with semicolons), and apply a strategy (e.g., min) for numeric fields like 'Year'\n",
    "            merged = {}\n",
    "            # For non-numeric fields, merge unique values\n",
    "            for col in ['Year', 'Country', 'Name of Invention', 'Name of Inventor', 'Category', 'General_Category']:\n",
    "                values = df.iloc[group][col].dropna().astype(str).tolist()\n",
    "                merged[col] = merge_dict_values(values)\n",
    "            # For normalized fields, keep the first item\n",
    "            merged['Invention_Norm'] = df.iloc[group[0]]['Invention_Norm']\n",
    "            merged_records.append(pd.Series(merged))\n",
    "    \n",
    "    return pd.DataFrame(merged_records)\n",
    "\n",
    "# Apply the deduplication function\n",
    "df_dedup = deduplicate_df(df_clean, threshold=90)\n",
    "print(\"Number of records before deduplication:\", len(df_clean))\n",
    "print(\"Number of records after deduplication:\", len(df_dedup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the first year if there are multiple (e.g. “1853; 1867”) and convert to int\n",
    "df_dedup['Year'] = (\n",
    "    df_dedup['Year']\n",
    "    .astype(str)\n",
    "    .str.split(';')   # split on semicolon\n",
    "    .str[0]           # take the first piece\n",
    "    .astype(int)      # convert to integer\n",
    ")\n",
    "\n",
    "# Now you can safely sort by Year\n",
    "df_dedup.sort_values(by='Year', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the final cleaned and deduplicated data, then save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the cleaned and deduplicated data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name of Invention</th>\n",
       "      <th>Name of Inventor</th>\n",
       "      <th>Category</th>\n",
       "      <th>General_Category</th>\n",
       "      <th>Invention_Norm</th>\n",
       "      <th>Inventor_Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed 18</th>\n",
       "      <td>1700</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Piano; The First Piano</td>\n",
       "      <td>Bartolomeo Cristofori</td>\n",
       "      <td>Music</td>\n",
       "      <td>Arts &amp; Media</td>\n",
       "      <td>piano</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>1701</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>mechanical seed drill</td>\n",
       "      <td>Jethro Tull</td>\n",
       "      <td>Agricultural Machinery</td>\n",
       "      <td>Agricultural Sciences &amp; Technology</td>\n",
       "      <td>mechanical seed drill</td>\n",
       "      <td>jethro tull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1709</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>used coke to smelt iron</td>\n",
       "      <td>Abraham Darby</td>\n",
       "      <td>Metallurgical Engineering</td>\n",
       "      <td>Chemistry &amp; Materials</td>\n",
       "      <td>used coke to smelt iron</td>\n",
       "      <td>abraham darby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed 19</th>\n",
       "      <td>1709</td>\n",
       "      <td>Germany; Poland</td>\n",
       "      <td>Alcohol Thermometer</td>\n",
       "      <td>Daniel Gabriel Fahrenheit; Gabriel Fahrenheit</td>\n",
       "      <td>Measurement Instrument; Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>alcohol thermometer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1712</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The First Commercial Steam Engine</td>\n",
       "      <td>Thomas Newcomen</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Engineering &amp; Technology</td>\n",
       "      <td>commercial steam engine</td>\n",
       "      <td>thomas newcomen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year          Country                  Name of Invention  \\\n",
       "Unnamed 18  1700            Italy             Piano; The First Piano   \n",
       "446         1701   United Kingdom              mechanical seed drill   \n",
       "448         1709   United Kingdom            used coke to smelt iron   \n",
       "Unnamed 19  1709  Germany; Poland                Alcohol Thermometer   \n",
       "141         1712   United Kingdom  The First Commercial Steam Engine   \n",
       "\n",
       "                                         Name of Inventor  \\\n",
       "Unnamed 18                          Bartolomeo Cristofori   \n",
       "446                                           Jethro Tull   \n",
       "448                                         Abraham Darby   \n",
       "Unnamed 19  Daniel Gabriel Fahrenheit; Gabriel Fahrenheit   \n",
       "141                                       Thomas Newcomen   \n",
       "\n",
       "                                   Category  \\\n",
       "Unnamed 18                            Music   \n",
       "446                  Agricultural Machinery   \n",
       "448               Metallurgical Engineering   \n",
       "Unnamed 19  Measurement Instrument; Physics   \n",
       "141                  Mechanical Engineering   \n",
       "\n",
       "                              General_Category           Invention_Norm  \\\n",
       "Unnamed 18                        Arts & Media                    piano   \n",
       "446         Agricultural Sciences & Technology    mechanical seed drill   \n",
       "448                      Chemistry & Materials  used coke to smelt iron   \n",
       "Unnamed 19                   Physical Sciences      alcohol thermometer   \n",
       "141                   Engineering & Technology  commercial steam engine   \n",
       "\n",
       "              Inventor_Norm  \n",
       "Unnamed 18              NaN  \n",
       "446             jethro tull  \n",
       "448           abraham darby  \n",
       "Unnamed 19              NaN  \n",
       "141         thomas newcomen  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final cleaned data has been saved to 'clean_data_dd.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"Preview of the cleaned and deduplicated data:\")\n",
    "display(df_dedup.head())\n",
    "\n",
    "# Remove the temporary normalization columns\n",
    "df_dedup.drop(['Invention_Norm', 'Inventor_Norm'], axis=1, inplace=True)\n",
    "\n",
    "df_dedup.to_csv('../../raw_data/clean_data/clean_data_dd.csv', index=False)\n",
    "print(\"The final cleaned data has been saved to 'clean_data_dd.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

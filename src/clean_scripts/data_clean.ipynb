{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Causes More Scientific Discoveries in Short Time\n",
    "\n",
    "## Data Clean\n",
    "\n",
    "- **Creating Author:** Yanheng Liu\n",
    "- **Latest Modification:** 13-04-2025  \n",
    "- **Modification Author:** Yanheng Liu  \n",
    "- **E-mail:** [yanheng.liu@etu.sorbonne-universite.fr](mailto:yanheng.liu@etu.sorbonne-universite.fr)  \n",
    "- **Version:** 1.2  \n",
    "\n",
    "---\n",
    "\n",
    "This is a data clean provided for the project in *DALAS* course.\n",
    "\n",
    "\n",
    "## Data Cleaning and Deduplication Workflow\n",
    "\n",
    "### Step 0: Check library installation\n",
    "\n",
    "### Step 1: Define Common Functions\n",
    "Includes text cleaning, normalization, and fuzzy matching functions.\n",
    "\n",
    "### Step 2: Load and Merge Data\n",
    "Reads three data files and merges them into a single DataFrame.\n",
    "\n",
    "### Step 3: Clean Punctuation\n",
    "Removes unnecessary punctuation from all columns (e.g., quotes), but keeps semicolons.\n",
    "\n",
    "### Step 4: Preview Country Names\n",
    "Displays original country names to check for inconsistencies manually.\n",
    "\n",
    "### Step 5: Standardize Country Names\n",
    "Uses a predefined mapping dictionary to unify country name variations.\n",
    "\n",
    "### Step 6: Preview Invention Categories\n",
    "Shows all original invention categories.\n",
    "\n",
    "### Step 7: Generalize Categories\n",
    "Maps specific invention categories to broader scientific fields, with detailed explanation.\n",
    "\n",
    "### Step 8: Normalize Key Text Fields\n",
    "Cleans and normalizes 'Name of Invention' and 'Name of Inventor' by lowering case and removing stopwords.\n",
    "\n",
    "### Step 9: Deduplicate Using Fuzzy Matching\n",
    "Groups similar invention names using fuzzy matching and merges records by combining field values.\n",
    "\n",
    "### Step 10: Output Final Dataset\n",
    "Displays the final cleaned dataset and saves it to a new CSV file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check package whether are installed in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already installed: requests\n",
      "Already installed: beautifulsoup4\n",
      "Already installed: pandas\n",
      "Already installed: tabulate\n",
      "Already installed: pdfplumber\n",
      "Already installed: lxml\n",
      "Already installed: pandas\n",
      "Installing missing package: fuzzywuzzy\n",
      "Requirement already satisfied: fuzzywuzzy in /Users/fire/opt/anaconda3/lib/python3.8/site-packages (0.18.0)\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import subprocess\n",
    "\n",
    "# Read package list from requirements.txt\n",
    "with open(\"../../requirements.txt\", \"r\") as file:\n",
    "    packages = [line.strip() for line in file if line.strip() and not line.startswith(\"#\")]\n",
    "\n",
    "# Get the list of currently installed packages\n",
    "installed_packages = {pkg.key for pkg in pkg_resources.working_set}\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in packages:\n",
    "    pkg_name = package.split(\"==\")[0].lower() if \"==\" in package else package.lower()\n",
    "    if pkg_name not in installed_packages:\n",
    "        print(f\"Installing missing package: {package}\")\n",
    "        try:\n",
    "            subprocess.check_call([\"pip\", \"install\", package])\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to install {package}. Error: {e}\")\n",
    "    else:\n",
    "        print(f\"Already installed: {package}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Functions\n",
    "The cell is used to import pandas, re, string and fuzzywuzzy related functions, and defines common text preprocessing, punctuation cleaning, country normalisation, invention category classification, text normalisation and fuzzy matching and de-emphasis and other basic functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Define a translation table to remove punctuation except semicolon\n",
    "punctuations = string.punctuation.replace(\";\", \"\")  # keep semicolon\n",
    "trans_table = str.maketrans('', '', punctuations)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation from text except semicolon.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Remove punctuation using the translation table\n",
    "        return text.translate(trans_table).strip()\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def normalize_text(text, stopwords=None):\n",
    "    \"\"\"Normalize text: lower-case, remove punctuation and stopwords, and extra spaces.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # lower-case\n",
    "    text = text.lower()\n",
    "    # remove punctuation (except semicolon)\n",
    "    text = text.translate(trans_table)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    if stopwords:\n",
    "        # remove stopwords provided as a set\n",
    "        tokens = text.split()\n",
    "        tokens = [t for t in tokens if t not in stopwords]\n",
    "        text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "def standardize_country(country_str, mapping):\n",
    "    \"\"\"\n",
    "    Standardize country names.\n",
    "    Split multiple countries by semicolon, map each to official name, then return unique sorted values.\n",
    "    \"\"\"\n",
    "    if not isinstance(country_str, str):\n",
    "        return country_str\n",
    "    # Split by semicolon and possibly comma if there is complex cases\n",
    "    parts = re.split(r'[;，,]', country_str)\n",
    "    standardized = []\n",
    "    for part in parts:\n",
    "        # Remove leading and trailing spaces and convert to lower case\n",
    "        part_clean = part.strip().lower()\n",
    "        if part_clean in mapping:\n",
    "            standardized.append(mapping[part_clean])\n",
    "        else:\n",
    "            # If not in the mapping, capitalise the first letter.\n",
    "            standardized.append(part_clean.title())\n",
    "    # De-weighting and sorting before joining with a semicolon\n",
    "    standardized = sorted(set(standardized))\n",
    "    return \"; \".join(standardized)\n",
    "\n",
    "def generalize_category(cat):\n",
    "    \"\"\"\n",
    "    Generalize specific invention categories into broader scientific fields.\n",
    "    Uses regex patterns to match keywords (case-insensitive) in each category.\n",
    "    \"\"\"\n",
    "    if not isinstance(cat, str):\n",
    "        return cat\n",
    "    cat_lower = cat.lower()\n",
    "    # Mapping rules: key is the matching pattern, value is the generic category after categorisation\n",
    "    mapping_rules = [\n",
    "        (r'\\b(physics|quantum|nuclear|astronomy|cosmology|astrophysics|geophysics|optics)\\b', 'Physical Sciences'),\n",
    "        (r'\\b(chemistry|chemical|biochemistry|electrochemistry|materials|metallurgical|industrial)\\b', 'Chemistry and Materials Science'),\n",
    "        (r'\\b(medicine|medical|genetics|virology|pharmaceutical|immunology|biotechnology)\\b', 'Life Sciences & Medicine'),\n",
    "        (r'\\b(engineering|computer|electronic|telecommunications|software|hardware|artificial intelligence|robotics|network|cryptography|tech|aerospace)\\b', 'Engineering and Technology'),\n",
    "        (r'\\b(biology|bio)\\b', 'Life Sciences & Medicine')\n",
    "    ]\n",
    "    for pattern, general in mapping_rules:\n",
    "        if re.search(pattern, cat_lower, re.IGNORECASE):\n",
    "            return general\n",
    "    return 'Other'\n",
    "\n",
    "def merge_dict_values(rows):\n",
    "    \"\"\"\n",
    "    Merge a list of values (e.g., country, inventor, etc.) by taking unique values and joining them with semicolon.\n",
    "    \"\"\"\n",
    "    merged = set()\n",
    "    for item in rows:\n",
    "        if isinstance(item, str):\n",
    "            # Splitting possible composite entries\n",
    "            parts = re.split(r'[;，,]', item)\n",
    "            for part in parts:\n",
    "                merged.add(part.strip())\n",
    "        else:\n",
    "            merged.add(str(item).strip())\n",
    "    return \"; \".join(sorted(merged))\n",
    "\n",
    "# Define a set of stopwords to remove in text cleaning for invention names\n",
    "stopwords = set(['the', 'for', 'of', 'and', 'in', 'on', 'origin', 'proposed', 'idea', 'first'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV files and merge data\n",
    "This cell reads three separate CSV files from this directory and merges them into a single DataFrame for unified processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of origin data： 445\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../../raw_data/clean_data/clean_data_yann_1.csv')\n",
    "df2 = pd.read_csv('../../raw_data/clean_data/clean_data_yann_2.csv')\n",
    "df3 = pd.read_csv('../../raw_data/clean_data/clean_data_yann_3.csv')\n",
    "\n",
    "# Concatenate all data into one DataFrame\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "print(\"number of origin data：\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleansing the data, removing punctuation and redundant spaces other than semicolons from each field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name of Invention</th>\n",
       "      <th>Name of Inventor</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Quantum theory proposed</td>\n",
       "      <td>Planck</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>AustrianAmerican</td>\n",
       "      <td>Discovery of human blood groups</td>\n",
       "      <td>Landsteiner</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Waveparticle duality of light</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Special theory of relativity</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1906</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Existence of vitamins proposed</td>\n",
       "      <td>Hopkins</td>\n",
       "      <td>Biochemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Country                Name of Invention Name of Inventor  \\\n",
       "0  1900           Germany          Quantum theory proposed           Planck   \n",
       "1  1901  AustrianAmerican  Discovery of human blood groups      Landsteiner   \n",
       "2  1905           Germany    Waveparticle duality of light         Einstein   \n",
       "3  1905           Germany     Special theory of relativity         Einstein   \n",
       "4  1906    United Kingdom   Existence of vitamins proposed          Hopkins   \n",
       "\n",
       "       Category  \n",
       "0       Physics  \n",
       "1      Medicine  \n",
       "2       Physics  \n",
       "3       Physics  \n",
       "4  Biochemistry  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Punctuation cleaning for all string type fields\n",
    "for col in df_clean.columns:\n",
    "    df_clean[col] = df_clean[col].apply(remove_punctuation)\n",
    "\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export all country names for inspection\n",
    "Extract unique values by combining all country fields into a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of original country names:\n",
      "Australia\n",
      "Australia; Switzerland\n",
      "Austria\n",
      "Austria; Netherlands\n",
      "Austria; Sweden\n",
      "AustrianAmerican\n",
      "Belgium\n",
      "Belgium; United States\n",
      "Britain\n",
      "Bulgaria\n",
      "Canada\n",
      "Croatia\n",
      "Czech\n",
      "Denmark\n",
      "Egyptian; Korean\n",
      "England\n",
      "Finland\n",
      "France\n",
      "France; Germany; United Kingdom\n",
      "Germany\n",
      "Germany; Austria\n",
      "Germany; Canada\n",
      "Germany; Denmark; Germany; Germany; Austria\n",
      "Germany; France\n",
      "Germany; USA\n",
      "Germany; United Kingdom\n",
      "Hungarian; British\n",
      "Hungary\n",
      "India\n",
      "Ireland\n",
      "Italy\n",
      "Italy; Germany\n",
      "Japan\n",
      "Japan; Dutch\n",
      "Japan; USA\n",
      "Mexico; USA\n",
      "Multiple\n",
      "Netherlands\n",
      "Netherlands; Japan\n",
      "New Zealand\n",
      "Norway\n",
      "Poland\n",
      "Poland; France\n",
      "Russia\n",
      "Russia; USA\n",
      "Scotland\n",
      "Serbia\n",
      "South Korea\n",
      "Soviet Union\n",
      "Sweden\n",
      "Switzerland\n",
      "USA\n",
      "USA; England\n",
      "USA; France\n",
      "USA; Germany\n",
      "USA; International\n",
      "USA; Japan\n",
      "USA; Pakistan\n",
      "USA; USA; Canada\n",
      "USA; United Kingdom\n",
      "United Kingdom\n",
      "United Kingdom; Australia\n",
      "United Kingdom; France\n",
      "United Kingdom; Germany\n",
      "United Kingdom; USA\n",
      "United Kingdom; United States\n",
      "United Kingdom; United States; Israel\n",
      "United States\n",
      "United States; China\n",
      "United States; France\n",
      "United States; France; Japan\n",
      "United States; Germany\n",
      "United States; Italy\n",
      "United States; United Kingdom\n",
      "Wales\n"
     ]
    }
   ],
   "source": [
    "all_countries = df_clean['Country'].dropna().unique()\n",
    "print(\"List of original country names:\")\n",
    "for country in sorted(all_countries):\n",
    "    print(country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardised Country Names\n",
    "Define country similar name mapping (all keys are lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardised list of country names:\n",
      "Australia\n",
      "Australia; Switzerland\n",
      "Australia; United Kingdom\n",
      "Austria\n",
      "Austria; Denmark; Germany\n",
      "Austria; Germany\n",
      "Austria; Netherlands\n",
      "Austria; Sweden\n",
      "Austrianamerican\n",
      "Belgium\n",
      "Belgium; United States\n",
      "Bulgaria\n",
      "Canada\n",
      "Canada; Germany\n",
      "Canada; United States\n",
      "China; United States\n",
      "Croatia\n",
      "Czech\n",
      "Denmark\n",
      "Dutch; Japan\n",
      "Egyptian; Korean\n",
      "Finland\n",
      "France\n",
      "France; Germany\n",
      "France; Germany; United Kingdom\n",
      "France; Japan; United States\n",
      "France; Poland\n",
      "France; United Kingdom\n",
      "France; United States\n",
      "Germany\n",
      "Germany; Italy\n",
      "Germany; United Kingdom\n",
      "Germany; United States\n",
      "Hungarian; United Kingdom\n",
      "Hungary\n",
      "India\n",
      "International; United States\n",
      "Ireland\n",
      "Israel; United Kingdom; United States\n",
      "Italy\n",
      "Italy; United States\n",
      "Japan\n",
      "Japan; Netherlands\n",
      "Japan; United States\n",
      "Mexico; United States\n",
      "Multiple\n",
      "Netherlands\n",
      "New Zealand\n",
      "Norway\n",
      "Pakistan; United States\n",
      "Poland\n",
      "Russia\n",
      "Russia; United States\n",
      "Serbia\n",
      "South Korea\n",
      "Sweden\n",
      "Switzerland\n",
      "United Kingdom\n",
      "United Kingdom; United States\n",
      "United States\n"
     ]
    }
   ],
   "source": [
    "country_mapping = {\n",
    "    \"british\": \"United Kingdom\",\n",
    "    \"britain\": \"United Kingdom\",\n",
    "    \"england\": \"United Kingdom\",\n",
    "    \"wales\": \"United Kingdom\",\n",
    "    \"scotland\": \"United Kingdom\",\n",
    "    \"usa\": \"United States\",\n",
    "    \"us\": \"United States\",\n",
    "    \"soviet union\": \"Russia\",\n",
    "}\n",
    "\n",
    "# Standardise the Country field, using the standardize_country function defined previously\n",
    "df_clean['Country'] = df_clean['Country'].apply(lambda x: standardize_country(x, country_mapping))\n",
    "\n",
    "# Output standardised list of country names\n",
    "std_countries = df_clean['Country'].dropna().unique()\n",
    "print(\"Standardised list of country names:\")\n",
    "for c in sorted(std_countries):\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export all original invention categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of original invention categories:\n",
      "3D Printing\n",
      "Acoustics\n",
      "Aerospace\n",
      "Aerospace Engineering\n",
      "Agricultural Chemistry\n",
      "Agricultural Engineering\n",
      "Agricultural Machinery\n",
      "Agricultural Technology\n",
      "Agriculture\n",
      "Anthropology\n",
      "Artificial Intelligence\n",
      "Assistive Technology\n",
      "Astronomy\n",
      "Astrophysics\n",
      "Audio Technology\n",
      "Automotive Technology\n",
      "Aviation\n",
      "Aviation Technology\n",
      "Battery Technology\n",
      "Biochemistry\n",
      "Biology\n",
      "Biotechnology\n",
      "Blockchain Technology\n",
      "Chaos Theory\n",
      "Chemical Engineering\n",
      "Chemistry\n",
      "Civil Engineering\n",
      "Climate Science\n",
      "Climatology\n",
      "Communication Technology\n",
      "Communications\n",
      "Computer Engineering\n",
      "Computer Hardware\n",
      "Computer Interface\n",
      "Computer Networking\n",
      "Computer Science\n",
      "Computing\n",
      "Construction Engineering\n",
      "Construction Materials\n",
      "Consumer Electronics\n",
      "Cosmology\n",
      "Cryptography\n",
      "Data Storage\n",
      "Diving Technology\n",
      "Domestic Technology\n",
      "Electrical Engineering\n",
      "Electricity\n",
      "Electrochemistry\n",
      "Electronic Engineering\n",
      "Electronics\n",
      "Energy Technology\n",
      "Environmental Science\n",
      "Ethology\n",
      "Evolutionary Biology\n",
      "Explosives\n",
      "Film Technology\n",
      "Financial Technology\n",
      "Firearms Technology\n",
      "Food Technology\n",
      "Garment Technology\n",
      "Genetics\n",
      "Genomics\n",
      "Geology\n",
      "Geophysics\n",
      "Home Appliances\n",
      "Horology\n",
      "Hydraulic Engineering\n",
      "Immunology\n",
      "Industrial Design\n",
      "Industrial Engineering\n",
      "Industrial Machinery\n",
      "Industrial Process\n",
      "Information Technology\n",
      "Internet Technology\n",
      "Laser Technology\n",
      "Lock Technology\n",
      "Logistics\n",
      "Machine Tools\n",
      "Marine Navigation\n",
      "Marine Technology\n",
      "Materials Science\n",
      "Materials Technology\n",
      "Mathematics\n",
      "Measurement Instrument\n",
      "Mechanical Engineering\n",
      "Medical Equipment\n",
      "Medical Imaging\n",
      "Medicine\n",
      "Metallurgical Engineering\n",
      "Microbiology\n",
      "Microwave Technology\n",
      "Military Technology\n",
      "Mining Engineering\n",
      "Mining Technology\n",
      "Mobile Technology\n",
      "Molecular Biology\n",
      "Music\n",
      "Navigation Technology\n",
      "Neurology\n",
      "Neuroscience\n",
      "Nuclear Fusion\n",
      "Nuclear Physics\n",
      "Nuclear Science\n",
      "Nuclear Weapons\n",
      "Oceanography\n",
      "Oil and Gas\n",
      "Optical Storage\n",
      "Optics\n",
      "Optoelectronics\n",
      "Paleoanthropology\n",
      "Paleontology\n",
      "Paper Technology\n",
      "Pharmaceuticals\n",
      "Photography\n",
      "Physics\n",
      "Physiology\n",
      "Printing Technology\n",
      "Quantum Computing\n",
      "Radiometric Dating\n",
      "Recreational Technology\n",
      "Refrigeration Technology\n",
      "Renewable Energy\n",
      "Rocketry\n",
      "Safety Technology\n",
      "Sanitation Technology\n",
      "Semiconductor Technology\n",
      "Software\n",
      "Space Technology\n",
      "Technical Drawing\n",
      "Telecommunications\n",
      "Television Technology\n",
      "Textile Machinery\n",
      "Theoretical Physics\n",
      "Thermodynamics\n",
      "Timekeeping Technology\n",
      "Touchscreen Technology\n",
      "Toy\n",
      "Toys\n",
      "Transportation\n",
      "Transportation Engineering\n",
      "Vertical Transportation\n",
      "Video Games\n",
      "Virology\n",
      "Weapon Technology\n",
      "Welding Technology\n",
      "Wireless Communication\n"
     ]
    }
   ],
   "source": [
    "all_categories = df_clean['Category'].dropna().unique()\n",
    "print(\"List of original invention categories:\")\n",
    "for cat in sorted(all_categories):\n",
    "    print(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate invention categories into general categories\n",
    "Apply the generalize_category function to the Category column and create a new column General_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Category Statistics:\n",
      "General_Category\n",
      "Other                              177\n",
      "Engineering and Technology          87\n",
      "Physical Sciences                   71\n",
      "Chemistry and Materials Science     56\n",
      "Life Sciences & Medicine            54\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_clean['General_Category'] = df_clean['Category'].apply(generalize_category)\n",
    "\n",
    "# Print the statistics of the transformed categories\n",
    "print(\"General Category Statistics:\")\n",
    "print(df_clean['General_Category'].value_counts())\n",
    "\n",
    "# Explanation:\n",
    "# We use a keyword-based regex matching method to aggregate detailed categories into four major groups:\n",
    "# 1. Physical Sciences: includes keywords such as physics, quantum, nuclear, astronomy, cosmology, astrophysics, geophysics, optics, etc.\n",
    "# 2. Chemistry and Materials Science: includes keywords such as chemistry, chemical, biochemistry, electrochemistry, materials, metallurgical, etc.\n",
    "# 3. Life Sciences & Medicine: includes keywords such as medicine, medical, genetics, virology, pharmaceutical, immunology, biotechnology, biology, etc.\n",
    "# 4. Engineering and Technology: includes keywords such as engineering, computer, electronic, telecommunications, software, hardware, artificial intelligence, robotics, network, cryptography, aerospace, etc.\n",
    "# Categories that do not match any keywords are categorized as \"Other\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and normalization (unifying case, removing stopwords and whitespace, etc.)\n",
    "Normalize 'Name of Invention' as a basis for later deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name of Invention</th>\n",
       "      <th>Name of Inventor</th>\n",
       "      <th>Category</th>\n",
       "      <th>General_Category</th>\n",
       "      <th>Invention_Norm</th>\n",
       "      <th>Inventor_Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Quantum theory proposed</td>\n",
       "      <td>Planck</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>quantum theory</td>\n",
       "      <td>planck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Austrianamerican</td>\n",
       "      <td>Discovery of human blood groups</td>\n",
       "      <td>Landsteiner</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Life Sciences &amp; Medicine</td>\n",
       "      <td>discovery human blood groups</td>\n",
       "      <td>landsteiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Waveparticle duality of light</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>waveparticle duality light</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Special theory of relativity</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>special theory relativity</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1906</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Existence of vitamins proposed</td>\n",
       "      <td>Hopkins</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>Chemistry and Materials Science</td>\n",
       "      <td>existence vitamins</td>\n",
       "      <td>hopkins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Country                Name of Invention Name of Inventor  \\\n",
       "0  1900           Germany          Quantum theory proposed           Planck   \n",
       "1  1901  Austrianamerican  Discovery of human blood groups      Landsteiner   \n",
       "2  1905           Germany    Waveparticle duality of light         Einstein   \n",
       "3  1905           Germany     Special theory of relativity         Einstein   \n",
       "4  1906    United Kingdom   Existence of vitamins proposed          Hopkins   \n",
       "\n",
       "       Category                 General_Category  \\\n",
       "0       Physics                Physical Sciences   \n",
       "1      Medicine         Life Sciences & Medicine   \n",
       "2       Physics                Physical Sciences   \n",
       "3       Physics                Physical Sciences   \n",
       "4  Biochemistry  Chemistry and Materials Science   \n",
       "\n",
       "                 Invention_Norm Inventor_Norm  \n",
       "0                quantum theory        planck  \n",
       "1  discovery human blood groups   landsteiner  \n",
       "2    waveparticle duality light      einstein  \n",
       "3     special theory relativity      einstein  \n",
       "4            existence vitamins       hopkins  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_clean['Invention_Norm'] = df_clean['Name of Invention'].apply(lambda x: normalize_text(x, stopwords=stopwords))\n",
    "# Similarly, normalize 'Name of Inventor' if needed\n",
    "df_clean['Inventor_Norm'] = df_clean['Name of Inventor'].apply(lambda x: normalize_text(x))\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform data deduplication using a fuzzy matching algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records before deduplication: 445\n",
      "Number of records after deduplication: 435\n"
     ]
    }
   ],
   "source": [
    "def deduplicate_df(df, threshold=90):\n",
    "    \"\"\"\n",
    "    Use fuzzy matching to group similar invention names and merge rows.\n",
    "    The merging is performed by taking the union of all other column values.\n",
    "    \"\"\"\n",
    "    groups = []  # list to store groups, each group is a list of row indices\n",
    "    # List of normalized invention names\n",
    "    names = df['Invention_Norm'].tolist()\n",
    "    used_idx = set()\n",
    "    \n",
    "    for idx, name in enumerate(names):\n",
    "        if idx in used_idx:\n",
    "            continue\n",
    "        # Create a new group with the current index\n",
    "        group = [idx]\n",
    "        used_idx.add(idx)\n",
    "        for jdx in range(idx+1, len(names)):\n",
    "            if jdx in used_idx:\n",
    "                continue\n",
    "            # Compute fuzzy ratio between two normalized strings\n",
    "            ratio = fuzz.ratio(name, names[jdx])\n",
    "            if ratio >= threshold:\n",
    "                group.append(jdx)\n",
    "                used_idx.add(jdx)\n",
    "        groups.append(group)\n",
    "    \n",
    "    # Merge groups: for each group, merge the corresponding rows\n",
    "    merged_records = []\n",
    "    for group in groups:\n",
    "        # If the group has only one record, keep it as is\n",
    "        if len(group) == 1:\n",
    "            merged_records.append(df.iloc[group[0]])\n",
    "        else:\n",
    "            # Merge each column (join values with semicolons), and apply a strategy (e.g., min) for numeric fields like 'Year'\n",
    "            merged = {}\n",
    "            # For non-numeric fields, merge unique values\n",
    "            for col in ['Year', 'Country', 'Name of Invention', 'Name of Inventor', 'Category', 'General_Category']:\n",
    "                values = df.iloc[group][col].dropna().astype(str).tolist()\n",
    "                merged[col] = merge_dict_values(values)\n",
    "            # For normalized fields, keep the first item\n",
    "            merged['Invention_Norm'] = df.iloc[group[0]]['Invention_Norm']\n",
    "            merged_records.append(pd.Series(merged))\n",
    "    \n",
    "    return pd.DataFrame(merged_records)\n",
    "\n",
    "# Apply the deduplication function\n",
    "df_dedup = deduplicate_df(df_clean, threshold=90)\n",
    "print(\"Number of records before deduplication:\", len(df_clean))\n",
    "print(\"Number of records after deduplication:\", len(df_dedup))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the final cleaned and deduplicated data, then save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the cleaned and deduplicated data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name of Invention</th>\n",
       "      <th>Name of Inventor</th>\n",
       "      <th>Category</th>\n",
       "      <th>General_Category</th>\n",
       "      <th>Invention_Norm</th>\n",
       "      <th>Inventor_Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Quantum theory proposed</td>\n",
       "      <td>Planck</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>quantum theory</td>\n",
       "      <td>planck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Austrianamerican</td>\n",
       "      <td>Discovery of human blood groups</td>\n",
       "      <td>Landsteiner</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Life Sciences &amp; Medicine</td>\n",
       "      <td>discovery human blood groups</td>\n",
       "      <td>landsteiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Waveparticle duality of light</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>waveparticle duality light</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1905</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Special theory of relativity</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>special theory relativity</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1906</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Existence of vitamins proposed</td>\n",
       "      <td>Hopkins</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>Chemistry and Materials Science</td>\n",
       "      <td>existence vitamins</td>\n",
       "      <td>hopkins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Country                Name of Invention Name of Inventor  \\\n",
       "0  1900           Germany          Quantum theory proposed           Planck   \n",
       "1  1901  Austrianamerican  Discovery of human blood groups      Landsteiner   \n",
       "2  1905           Germany    Waveparticle duality of light         Einstein   \n",
       "3  1905           Germany     Special theory of relativity         Einstein   \n",
       "4  1906    United Kingdom   Existence of vitamins proposed          Hopkins   \n",
       "\n",
       "       Category                 General_Category  \\\n",
       "0       Physics                Physical Sciences   \n",
       "1      Medicine         Life Sciences & Medicine   \n",
       "2       Physics                Physical Sciences   \n",
       "3       Physics                Physical Sciences   \n",
       "4  Biochemistry  Chemistry and Materials Science   \n",
       "\n",
       "                 Invention_Norm Inventor_Norm  \n",
       "0                quantum theory        planck  \n",
       "1  discovery human blood groups   landsteiner  \n",
       "2    waveparticle duality light      einstein  \n",
       "3     special theory relativity      einstein  \n",
       "4            existence vitamins       hopkins  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final cleaned data has been saved to 'clean_data_dd.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"Preview of the cleaned and deduplicated data:\")\n",
    "display(df_dedup.head())\n",
    "\n",
    "# Save to a new CSV file to avoid overwriting the original file\n",
    "df_dedup.to_csv('../../raw_data/clean_data/clean_data_dd.csv', index=False)\n",
    "print(\"The final cleaned data has been saved to 'clean_data_dd.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
